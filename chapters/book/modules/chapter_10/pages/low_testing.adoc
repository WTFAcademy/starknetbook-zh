[id="low_testing"]

= 低度测试：简洁的秘诀

算术化的过程使我们能够将计算完整性（ CI ）问题简化为低度测试问题。低度测试是指通过对函数进行少量查询，来判断给定函数是否为某个受限度数的多项式的问题。低度测试已经被研究了二十多年，是概率证明理论中的核心工具。本文的目的是更详细地解释低度测试，并描述我们在 STARK 中用于低度测试的协议 FRI。本文假定读者熟悉有限域上的多项式。

在我们讨论低度测试之前，我们先通过一个稍微简单的问题来进行热身：给定一个函数，并要求我们通过在“少量”位置上查询该函数，来判断这个函数是否等于某个常数d 的多项式。正式地说，给定域 F 的子集 L 和受限度数 d，我们希望确定 $f:L➝F$ 是否等于度数小于 $d$ 的多项式，即是否存在一个多项式。

image::low1.png[low1]

其存在于域 $F$ 上，对于$L$中的每个$a$，$p(a)=f(a)$。对于具体的数值，你可以考虑一个规模非常大的域，比如2¹²⁸$，而 $L$ 的规模大约为10,000,000。

解决此问题需要在整个域 $L$ 中查询 $f$，因为 f 可能与 $L$ 的任何地方的多项式一致，除了一个位置之外。即使我们允许恒定的错误概率，查询的数量仍然与 $L$ 的大小成线性关系。

[cols=3*]
|===
| 为此，低度测试问题实际上是对上述问题的一种近似放宽，它足以构造概率证明，也可以用查询次数来解决，查询次数的对数是$
| L
| $（请注意，如果 $L≈10,000,000$，则 $log₂(L)≈23）$。更详细地说，我们希望区分以下两种情况。
|===

* *函数 $f$ 等于一个低度多项式。*。也就是说，存在一个多项式 $p(x)$ 在 $F$ 上，度数小于 $d$，并且在 $L$ 上处处与 $f$ 一致。
* *函数 $f$ 与所有低度多项式相差甚远*。 例如，我们需要修改至少 10% 的 $f$ 值，才能获得一个符合小于 $d$ 的多项式的函数。

请注意，还有另一种可能性 -- 函数 $f$ 可能略微接近低度多项式，但不等于 1。例如，一个 $5%$ 的值与低度多项式不同的函数，不属于上述两种情况中的任何一种。然而，先前的算术化步骤（在我们之前的帖子中讨论过）确保第三种情况永远不会出现。更详细地说，算术化表明处理真实声明的诚实证明器将落入第一种情况，而试图“证明”错误声明的（可能是恶意的）证明器将很有可能落入第二种情况。

为了区分这两种情况，我们将使用一个概率多项式时间测试，在少量位置查询 f（我们稍后讨论“少量”的含义）。

[cols=3*]
|===
| | 这一段是可有可无的，主要用于理解全局。如果 $f$ 确实是低度的，那么测试应该以 1 的概率接受。如果 f 远非低度，那么测试应该以高概率拒绝。更通俗地说，我们寻求保证，如果 f 与任何度数小于 d 的函数 $δ-相差$（即必须修改至少 $δ
| L
| $ 的位置以获得度数小于 d 的多项式），然后该测试以至少 $Ω(δ)$ 的概率拒绝（或 $δ$ 的一些其他“好”函数）。直觉上，$δ$ 越接近零，就越难区分这两种情况。
|===

在接下来的几节中，我们描述了一个简单的测试，然后解释了为什么它在我们的设置中不够用，最后我们描述了一个效率成倍增加的、更复杂的测试。后一种测试是我们在 STARK 中使用的测试。

== 直接测试

[cols=3*]
|===
| 我们考虑的第一个测试很简单：它使用 $d+1$ 查询来测试函数是否（接近）度数小于 $d$ 的多项式。这个测试依赖于有关多项式的一个基本事实：任何度数小于 d 的多项式完全由它在 $F$ 的任何 d 个不同位置的值决定。这个事实是一个直接的结果，即一个度数为 $k$ 的多项式在 $F$ 中最多可以有 $k$的根。重要的是，查询的数量，即 $d+1$，可以明显小于 $f$ 的域大小，即 $
| L
| $。
|===

我们首先讨论两个简单的特殊情况，以建立对测试在一般情况下如何工作的直觉。

* *常数函数 $(d=1)$ 的情况。* 这对应于区分 $f$ 是常数函数的情况（$f(x)=c$ for some $c$ in $F$）和 $f$ 远离任何常数函数的情况功能。在这种特殊情况下，有一个自然的 2 次查询测试可能有效：在固定位置 $z1$ 和随机位置 $w$ 查询 $f$，然后检查 $f(z1)=f(w )$。直观地说，$f(z1)$ 决定了 $f$ 的（所谓的）常数值，$f(w)$ 测试是否所有的 $f$ 都接近这个常数值。
* *线性函数 $(d=2)$ 的情况。* 这对应于区分 $f$ 是线性函数的情况（$f(x)=ax+b$ for some $a$,$b$ in $F$）和 $f$ 远离任何线性函数的情况。在这种特殊情况下，有一个自然的 3 次查询测试可能有效：在两个固定位置 z1、z2 和随机位置 $w$ 查询 f，然后检查 ($z1$,$f(z1)$ ), ($z2$,$f(z2)$)、($w$,$f(w)$) 是否成线性，即可以通过这些点将其贯穿成一条线。直观地说，$f(z1)$ 和 $f(z2)$ 的值决定了（所谓的）线，而 $f(w)$ 测试了 $f$ 的全部是否接近这条线。

上述特殊情况提示了一种针对受限度数 $d$ 的通用情况进行测试。在 $d$ 次固定位置 $z1$、$z2$、$… $、$zd$ 以及随机位置 $w$ 处查询 $f$。 $f$ 在 $z0$,$z1$,$… $,$zd$ 的值定义了一个唯一的多项式 $h(x)$，其度数小于 $d$，超过 $F$，与 $f$在这些点上保持一致。然后测试检查 $h(w)=f(w)$。我们称之为直接测试。

根据定义，如果 $f(x)$ 等于次数小于 $d$ 的多项式 $p(x)$，则 $h(x)$ 将与 $p(x)$ 完全相同，因此直接测试以概率 1 通过。此属性称为“完美完整性”，这意味着此测试只有单边误差。

我们要争论的是，如果$f$与任何度数小于 $d$ 的函数相差 $δ$，会发生什么情况（例如，考虑 $δ=10%$。）我们现在要争论的是，在这种情况下，直接测试以至少 δ 的概率拒绝。事实上，设 𝞵 是随机选择 w，则 $h(w)≠f(w)$。我们观察到 $𝞵$ 必须至少为 δ。可选的：这是因为如果我们假设 𝞵 小于 δ，那么我们推断 f 是 δ 接近 h，这与我们假设 f 是 δ 远离任何小于 d 的函数的假设相矛盾。

== The Direct Test Does Not Suffice For Us

In our setting we are interested in testing functions f:L➝F that encode computation traces, and hence whose degree d (and domain L) are quite large. Merely running the direct test, which makes d+1 queries, would be too expensive. In order to gain the exponential savings of STARK (in verification time compared to the size of the computation trace), we need to solve this problem with only O(log d) queries, which is exponentially less than the degree bound d.

This, unfortunately, is impossible because if we query f at less than d+1 locations then we cannot conclude anything.

Optional: One way to see this is to consider two different distributions of functions f:L➝F. In one distribution we uniformly pick a polynomial of degree exactly d and evaluate it on L. In the other distribution we uniformly pick a polynomial of degree less than d and evaluate it on L. In both cases, for any d locations z1,z2,...,zd, the values f(z1),f(z2),...,f(zd) are uniformly and independently distributed. (We leave this fact as an exercise for the reader.) This implies that information-theoretically we cannot tell these two cases apart, even though a test would be required to (since polynomials from the first distribution should be accepted by the test while those of degree exactly d are very far from all polynomials of degree less than d, and thus should be rejected).

We seem to have a difficult challenge to overcome.

== A Prover Comes to the Rescue

We have seen that we need d+1 queries to test that a function f:L➝F is close to a polynomial of degree less than d, but we cannot afford this many queries. We avoid this limitation by considering a slightly different setting, which suffices for us. Namely, we consider the problem of low degree testing when a prover is available to supply useful auxiliary information about the function f. We will see that in this "`prover-aided`" setting of low-degree testing we can achieve an exponential improvement in the number of queries, to O(log d).

In more detail, we consider a protocol conducted between a prover and a verifier, wherein the (untrusted) prover tries to convince the verifier that the function is of low degree. On the one hand, the prover knows the entire function f being tested. On the other hand, the verifier can query the function f at a small number of locations, and is willing to receive help from the prover, but does NOT trust the prover to be honest. This means that the prover may cheat and not follow the protocol. However, if the prover does cheat, the verifier has the liberty to "`reject`", regardless of whether the function f is of low degree or not. The important point here is that the verifier will not be convinced that f is of low degree unless this is true.

Note that the direct test described above is simply the special case of a protocol in which the prover does nothing, and the verifier tests the function unassisted. To do better than the direct test we will need to leverage the help of the prover in some meaningful way.

Throughout the protocol the prover will want to enable the verifier to query auxiliary functions on locations of the verifier's choice. This can be achieved via commitments, a mechanism that we will discuss in a future blog post. For now it suffices to say that the prover can commit to a function of its choice via a Merkle tree, and subsequently the verifier can request the prover to reveal any set of locations of the committed function. The main property of this commitment mechanism is that once the prover commits to a function, it must reveal the correct values and cannot cheat (for example, it cannot decide what the values of the function are after seeing the requests from the verifier).

== Halving the number of queries for the case of two polynomials

Let's start with a simple example that illustrates how a prover can help to reduce the number of queries by a factor of 2. We will later build on this example. Suppose that we have two polynomials f and g and we want to test that they are both of degree less than d. If we simply run the direct test individually on f and g then we would need to make 2 * (d + 1) queries. Below we describe how with the help of a prover we can reduce the number of queries to (d + 1) plus a smaller-order term.

First, the verifier samples a random value 𝛼 from the field and sends it to the prover. Next, the prover replies by committing to the evaluation on the domain L (recall that L is the domain of the function f) of the polynomial h(x) = f(x) + 𝛼 g(x) (in other words, the prover will compute and send the root of a Merkle tree whose leaves are the values of h on L). The verifier now tests that h has degree less than d, via the direct test, which requires d+1 queries.

[cols=5*]
|===
| Intuitively, if f or g has degree at least d, then with high probability so does h. For example, consider the case where the coefficient of xⁿ in f is not zero for some n≥d. Then, there is at most one choice of 𝛼 (sent by the verifier) for which the coefficient of xⁿ in h is zero, which means that the probability that h has degree less than d is roughly 1/
| F
| . If the field is large enough (say,
| F
| >2¹²⁸), the probability of error is negligible.
|===

The situation, however, is not this simple. The reason is that, as we explained, we cannot literally check that h is a polynomial of degree less than d. Instead we only can check that h is close to such a polynomial. This means that the analysis above is not accurate. Is it possible that f will be far from a low degree polynomial and the linear combination h will be close to one with a non-negligible probability over 𝛼? Under mild conditions the answer is no (which is what we want), but it is outside the scope for this post; we refer the interested reader to https://acmccs.github.io/papers/p2087-amesA.pdf[this paper] and https://eccc.weizmann.ac.il/report/2017/134/[this paper].

Moreover, how does the verifier know that the polynomial h sent by the prover has the form f(x)+𝛼 g(x)? A malicious prover may cheat by sending a polynomial which is indeed of low degree, but is different from the linear combination that the verifier asked for. If we already know that h is close to a low degree polynomial, then testing that this low degree polynomial has the correct form is straightforward: the verifier samples a location z in L at random, queries f, g, h at z, and checks that the equation h(z)=f(z)+𝛼 g(z) holds. This test should be repeated multiple times to increase accuracy of the test, but the error shrinks exponentially with the number of samples we make. Hence this step increases the number of queries (which so far was d+1) only by a smaller-order term.

== Splitting a polynomial into two smaller-degree polynomials

We saw that, with the prover's help, we can test that two polynomials are of degree less than d with less than 2*(d+1) queries. We now describe how we can turn one polynomial of degree less than d into two polynomials of degree less than d/2.

Let f(x) be a polynomial of degree less than d and assume that d is even (in our setting this comes without loss of generality). We can write f(x)=g(x²)+xh(x²) for two polynomials g(x) and h(x) of degree less than d/2. Indeed, we can let g(x) be the polynomial obtained from the even coefficients of f(x), and h(x) be the polynomial obtained from the odd coefficients of f(x). For example, if d=6 we can write

image::smallerPol1.png[smallerPol1]

which means that

image::smallerPol2.png[smallerPol2]

and

image::smallerPol3.png[smallerPol3]

which is an n*log(n) algorithm for polynomial evaluation (improving over the naive n2 algorithm).

[NOTE]
====
The Book is a community-driven effort created for the community.

* If you've learned something, or not, please take a moment to provide feedback through https://a.sprig.com/WTRtdlh2VUlja09lfnNpZDo4MTQyYTlmMy03NzdkLTQ0NDEtOTBiZC01ZjAyNDU0ZDgxMzU=[this 3-question survey].
* If you discover any errors or have additional suggestions, don't hesitate to open an https://github.com/starknet-edu/starknetbook/issues[issue on our GitHub repository].
====

== Contributing

[quote, The Starknet Community]
____
*Unleash Your Passion to Perfect StarknetBook*

StarknetBook is a work in progress, and your passion, expertise, and unique insights can help transform it into something truly exceptional. Don't be afraid to challenge the status quo or break the Book! Together, we can create an invaluable resource that empowers countless others.

Embrace the excitement of contributing to something bigger than ourselves. If you see room for improvement, seize the opportunity! Check out our https://github.com/starknet-edu/starknetbook/blob/main/CONTRIBUTING.adoc[guidelines] and join our vibrant community. Let's fearlessly build Starknet! 
____
